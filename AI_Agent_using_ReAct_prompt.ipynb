{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Gnp159BCclF8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "1e2a92fb-e615-4b47-9268-783d326395ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.3.19-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.63 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.3.63)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.82.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.9.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.126 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.63->langchain_openai) (0.3.43)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.63->langchain_openai) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.63->langchain_openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.63->langchain_openai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.63->langchain_openai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.63->langchain_openai) (4.13.2)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.63->langchain_openai) (2.11.5)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain_openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.63->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.63->langchain_openai) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.63->langchain_openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.63->langchain_openai) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.63->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.63->langchain_openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.63->langchain_openai) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.4.0)\n",
            "Downloading langchain_openai-0.3.19-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.5/64.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain_openai\n",
            "Successfully installed langchain_openai-0.3.19\n"
          ]
        }
      ],
      "source": [
        "!pip install requests\n",
        "!pip install langchain_openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# React Agent from scratch"
      ],
      "metadata": {
        "id": "tW52WXhYINi4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import requests\n",
        "from zoneinfo import ZoneInfo\n",
        "from abc import ABC, abstractmethod\n",
        "import json\n",
        "\n",
        "class Tool(ABC):\n",
        "    @abstractmethod\n",
        "    def name(self) -> str:\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def description(self) -> str:\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def use(self, *args, **kwargs):\n",
        "        pass\n",
        "\n",
        "class TimeTool(Tool):\n",
        "    def name(self):\n",
        "        return \"Time Tool\"\n",
        "\n",
        "    def description(self):\n",
        "        return \"Provides the current time for a given city's timezone like Asia/Kolkata, America/New_York etc. If no timezone is provided, it returns the local time.\"\n",
        "\n",
        "    def args(self):\n",
        "        return \"{'timezone': ''}\"\n",
        "\n",
        "    def use(self, args, **kwargs):\n",
        "        format = \"%Y-%m-%d %H:%M:%S %Z%z\"\n",
        "        current_time = datetime.datetime.now()\n",
        "        try:\n",
        "          input_timezone = args['timezone']\n",
        "          if input_timezone:\n",
        "              print(\"TimeZone\", input_timezone)\n",
        "              current_time =  current_time.astimezone(ZoneInfo(input_timezone))\n",
        "        except Exception as e:\n",
        "          pass\n",
        "        return f\"Couldn't fetch timezone details.\"\n",
        "\n",
        "class FlightDetails(Tool):\n",
        "    def name(self):\n",
        "        return \"Flight details Tool\"\n",
        "\n",
        "    def description(self):\n",
        "        return \"Provides flight details between the provided cities(origin and destination) and given date.\"\n",
        "\n",
        "    def args(self):\n",
        "        return \"{'origin':'','destination':'','date':''}\"\n",
        "\n",
        "    def use(self, args, **kwargs):\n",
        "        try:\n",
        "          src = args['origin']\n",
        "          dest = args['destination']\n",
        "          date = args['date']\n",
        "          if not src or not dest:\n",
        "            return \"Provide details of your origin and destination airports\"\n",
        "          if not date:\n",
        "            return \"Provide dates for your trip.\"\n",
        "          else:\n",
        "            return f\"\"\"{src} - {dest} - {date} Flight details: \\n\n",
        "                    1) Indigo : 7:00 AM\n",
        "                    2) AirIndia: 8:00 AM \"\"\"\n",
        "        except Exception as e:\n",
        "          return \"Couldn't fetch flight details\"\n",
        "\n",
        "class WeatherTool(Tool):\n",
        "    def name(self):\n",
        "        return \"Weather Tool\"\n",
        "\n",
        "    def description(self):\n",
        "        return \"Provides weather information for a given location\"\n",
        "\n",
        "    def args(self):\n",
        "        return \"{'location': ''}\"\n",
        "\n",
        "    def use(self, args, **kwargs):\n",
        "      try:\n",
        "        location = args['location']\n",
        "        temp = 35\n",
        "        return f\"The weather in {location} is currently {temp}°C.\"\n",
        "      except:\n",
        "        return f\"Couldn't fetch weather details for {location}\"\n",
        "\n",
        "class AskUser(Tool):\n",
        "    def name(self):\n",
        "        return \"Input Tool\"\n",
        "\n",
        "    def description(self):\n",
        "        return \"Get inputs from a user\"\n",
        "\n",
        "    def args(self):\n",
        "        return \"{'question': ''}\"\n",
        "\n",
        "    def use(self, args, **kwargs):\n",
        "      try:\n",
        "        question = args['question']\n",
        "        answer = input(f\"Question: {question}\\n Your Answer: \")\n",
        "        return f\"The answer to this question {question} is:  {answer}\"\n",
        "      except:\n",
        "        return f\"Couldn't get the answer\"\n",
        "\n",
        "class PopulationLookup(Tool):\n",
        "    def name(self):\n",
        "        return \"Population Tool\"\n",
        "\n",
        "    def description(self):\n",
        "        return \"Get population for the given country\"\n",
        "\n",
        "    def args(self,country=\"\"):\n",
        "        json_dict = {'country':country}\n",
        "        json_str = json.dumps(json_dict)\n",
        "        return json_str\n",
        "\n",
        "    def use(self, args, **kwargs):\n",
        "      try:\n",
        "        country = args['country']\n",
        "        if country==\"India\":\n",
        "          return f\"Population of this country is 5500000\"\n",
        "        if country==\"USA\":\n",
        "          return f\"Population of this country is 300000\"\n",
        "        if country==\"UK\":\n",
        "          return f\"Population of this country is 1500000\"\n",
        "\n",
        "      except:\n",
        "        return f\"Couldn't get the answer\"\n",
        "\n",
        "class MathTool(Tool):\n",
        "    def name(self):\n",
        "        return \"Math Tool\"\n",
        "\n",
        "    def description(self):\n",
        "        return \"Math Tool\"\n",
        "\n",
        "    def args(self,operation=\"\",inputs=\"[list of integers]\"):\n",
        "        json_dict = {'operation': operation,'inputs':inputs}\n",
        "        json_str = json.dumps(json_dict)\n",
        "        return json_str\n",
        "\n",
        "    def use(self, args, **kwargs):\n",
        "      try:\n",
        "        if args[\"operation\"]==\"+\":\n",
        "          inputs = args[\"inputs\"]\n",
        "          return int(inputs[0]) + int(inputs[1])\n",
        "        else:\n",
        "          return 150\n",
        "\n",
        "      except:\n",
        "        return f\"Couldn't get the answer\"\n"
      ],
      "metadata": {
        "id": "Zw_ImXRbdli4"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PopulationLookup().args(\"India\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "1P8yDiFdVD5h",
        "outputId": "66d54c96-258e-4a0a-a0ba-7014fb5a19cf"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"country\": \"India\"}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "import re\n",
        "import os\n",
        "import json\n",
        "import requests\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import Dict, Any\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "class Agent:\n",
        "    def __init__(self):\n",
        "        self.tools = []\n",
        "        self.memory = []\n",
        "        self.messages = []\n",
        "        self.max_memory = 10\n",
        "        self.llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "    def add_tool(self, tool: Tool):\n",
        "        self.tools.append(tool)\n",
        "\n",
        "    def json_parser(self, input_string):\n",
        "      try:\n",
        "        json_dict = eval(input_string)\n",
        "      except:\n",
        "        return \"Invalid JSON response\"\n",
        "\n",
        "      if isinstance(json_dict, dict):\n",
        "        return json_dict\n",
        "\n",
        "      raise \"Invalid JSON response\"\n",
        "\n",
        "    def parse_response(self,response: str):\n",
        "        \"\"\"\n",
        "        Parse the LLM response to extract and validate JSON content.\n",
        "        \"\"\"\n",
        "        stack = []\n",
        "        result = \"\"\n",
        "        for i, char in enumerate(response):\n",
        "            if char == \"{\":\n",
        "                if not stack:  # Start of the outermost block\n",
        "                    start = i\n",
        "                stack.append(\"{\")\n",
        "            elif char == \"}\":\n",
        "                stack.pop()\n",
        "                if not stack:  # End of the outermost block\n",
        "                    result = response[start:i+1]\n",
        "                    break\n",
        "\n",
        "        response_dict = self.json_parser(result)\n",
        "\n",
        "        return response_dict\n",
        "\n",
        "    def get_system_prompt(self):\n",
        "\n",
        "        tool_descriptions = \"\\n\".join([f\"- {tool.name()}: {tool.description()}\" for tool in self.tools])\n",
        "        tool_args = \"\\n\".join([f\"- {tool.name()}: {tool.args()}\" for tool in self.tools])\n",
        "        tool_names = \",\".join([tool.name() for tool in self.tools])\n",
        "        system_prompt = f'''Answer the following questions as best you can. You have access to the following tools:\n",
        "\n",
        "                      {tool_descriptions}\n",
        "\n",
        "                      Use the following format:\n",
        "\n",
        "                      Thought: you should always think about what to do\n",
        "                      Action: the action to take, should be one of the tools : [{tool_names}]\n",
        "                      Action Input: the input to the action. Argument format is [{tool_args}]\n",
        "                      PAUSE\n",
        "                      You will be called again with this:\n",
        "                      Observation: the result of the action\n",
        "                      ... (this Thought/Action/Action Input/Observation can repeat N times)\n",
        "                      Thought: I now know the final answer\n",
        "                      Final Answer: the final answer to the original input question\n",
        "\n",
        "                      If you decide to answer directly without using any tools then reply in \"Final Answer\" as your response.\n",
        "                      '''\n",
        "        return system_prompt\n",
        "\n",
        "    def process_input(self):\n",
        "\n",
        "        if len(self.messages)>self.max_memory:\n",
        "          system_msg = self.messages[0]\n",
        "          self.messages = [system_msg] + self.messages[-self.max_memory:]\n",
        "\n",
        "        response = self.llm.invoke(self.messages)\n",
        "\n",
        "        if \"Action\" in response.content and \"Action Input\" in response.content:\n",
        "          temp_chunk = response.content.split(\"Action:\")\n",
        "          thought = temp_chunk[0].split(\"Thought:\")[-1].strip()\n",
        "          print(\"Thought:\",thought)\n",
        "          action_name = temp_chunk[-1].split(\"Action Input:\")[0].strip()\n",
        "          print(\"Action name: \",action_name)\n",
        "          action_args = self.parse_response(response.content)\n",
        "          print(\"Action input: \",action_args)\n",
        "          for tool in self.tools:\n",
        "              if tool.name().lower() == action_name.lower():\n",
        "                  tool_res = tool.use(action_args)\n",
        "                  print(\"Observation: \",tool_res)\n",
        "                  return \"continue\",response.content + f\"\\n Observation: {tool_res}\"\n",
        "          print(\"--------------------------\")\n",
        "\n",
        "        if \"Final Answer:\" in response.content:\n",
        "          return \"stop\",response.content.split(\"Final Answer:\")[-1].strip()\n",
        "\n",
        "        return \"stop\",response.content\n",
        "\n",
        "    def run(self):\n",
        "      print(\"LLM Agent: Hello! How can I assist you today?\")\n",
        "      user_input = input(\"User: \")\n",
        "\n",
        "      self.messages = [\n",
        "                  (\"system\", self.get_system_prompt()),\n",
        "                  (\"human\", user_input ),\n",
        "              ]\n",
        "      i = 1\n",
        "\n",
        "      while True:\n",
        "        i+=1\n",
        "        if i==20:\n",
        "          break\n",
        "\n",
        "        if user_input and user_input.lower() in [\"exit\", \"bye\", \"close\"]:\n",
        "          print(\"See you later!\")\n",
        "          break\n",
        "\n",
        "        flag, response = self.process_input()\n",
        "        if flag == \"continue\":\n",
        "            self.messages.append((\"assistant\",response))\n",
        "        else:\n",
        "            print(\"LLM Agent: \", response)\n",
        "            self.messages.append((\"assistant\",response))\n",
        "            user_input = input(\"\\nUser: \")\n",
        "            self.messages.append((\"human\",user_input))"
      ],
      "metadata": {
        "id": "zT8Rvbp7dGzg"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "def main():\n",
        "    agent = Agent()\n",
        "    agent.add_tool(TimeTool())\n",
        "    agent.add_tool(WeatherTool())\n",
        "    agent.add_tool(FlightDetails())\n",
        "    agent.add_tool(AskUser())\n",
        "    agent.add_tool(MathTool())\n",
        "    agent.add_tool(PopulationLookup())\n",
        "    agent.run()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "L9NpVfKndr5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73306ac0-cd21-42ce-ccb2-9b130593ea70"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM Agent: Hello! How can I assist you today?\n",
            "User: whats the weather today?\n",
            "Thought: I need to know the location for which the weather is being requested.\n",
            "Action name:  Input Tool\n",
            "Action input:  {'question': 'Please provide the location for which you want to know the weather.'}\n",
            "Question: Please provide the location for which you want to know the weather.\n",
            " Your Answer: Mumbai\n",
            "Observation:  The answer to this question Please provide the location for which you want to know the weather. is:  Mumbai\n",
            "Thought: Now that I have the location, I can check the weather for Mumbai.\n",
            "Action name:  Weather Tool\n",
            "Action input:  {'location': 'Mumbai'}\n",
            "Observation:  The weather in Mumbai is currently 35°C.\n",
            "LLM Agent:  The weather today in Mumbai is currently 35°C.\n",
            "\n",
            "User: bye\n",
            "See you later!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# React Agent using Langchain"
      ],
      "metadata": {
        "id": "1lXHxKQh3TST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -U langchain_openai langchain-community langgraph langchain-anthropic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6Sj2ztCnazfE",
        "outputId": "d44afa71-2555-4f64-bd70-88a7cc88ae28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.10/dist-packages (0.2.14)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.3.14)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.10/dist-packages (0.2.61)\n",
            "Requirement already satisfied: langchain-anthropic in /usr/local/lib/python3.10/dist-packages (0.3.1)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.27 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.3.29)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.59.3)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.8.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.11.11)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.14 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.14)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.10)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from langgraph) (2.0.9)\n",
            "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /usr/local/lib/python3.10/dist-packages (from langgraph) (0.1.51)\n",
            "Requirement already satisfied: anthropic<1,>=0.41.0 in /usr/local/lib/python3.10/dist-packages (from langchain-anthropic) (0.42.0)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from langchain-anthropic) (0.7.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain-anthropic) (2.10.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from anthropic<1,>=0.41.0->langchain-anthropic) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from anthropic<1,>=0.41.0->langchain-anthropic) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from anthropic<1,>=0.41.0->langchain-anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from anthropic<1,>=0.41.0->langchain-anthropic) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from anthropic<1,>=0.41.0->langchain-anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.10/dist-packages (from anthropic<1,>=0.41.0->langchain-anthropic) (4.12.2)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.25.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.14->langchain-community) (0.3.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain_openai) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain_openai) (24.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.4->langgraph) (1.1.0)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.10/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.13)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-anthropic) (2.27.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic<1,>=0.41.0->langchain-anthropic) (1.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic<1,>=0.41.0->langchain-anthropic) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic<1,>=0.41.0->langchain-anthropic) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.27->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"]=\"pr-smug-toenail-81\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get(\"LANGCHAIN_API_KEY\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "5_enYjXRQGvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful assistant. Please respond to the user's request only based on the given context.\"),\n",
        "    (\"user\", \"Question: {question}\\nContext: {context}\")\n",
        "])\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "chain = prompt | model | output_parser\n",
        "\n",
        "question = \"Can you summarize this morning's meetings?\"\n",
        "context = \"During this morning's meeting, we solved all world conflict.\"\n",
        "chain.invoke({\"question\": question, \"context\": context})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Jms3832Yfhf6",
        "outputId": "cdcea7ad-10a5-42b1-de17-003624f0d886"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"This morning's meeting successfully addressed and resolved all world conflicts.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from langsmith import wrappers, traceable\n",
        "\n",
        "# Auto-trace LLM calls in-context\n",
        "client = wrappers.wrap_openai(openai.Client())\n",
        "\n",
        "@traceable # Auto-trace this function\n",
        "def pipeline(user_input: str):\n",
        "    result = client.chat.completions.create(\n",
        "        messages=[{\"role\": \"user\", \"content\": user_input}],\n",
        "        model=\"gpt-4o-mini\"\n",
        "    )\n",
        "    return result.choices[0].message.content\n",
        "\n",
        "pipeline(\"Hello, world!\")\n",
        "# Out:  Hello there! How can I assist you today?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "tJW45K2lqqVU",
        "outputId": "28845f0b-8b6d-41c5-885a-9cf75fbbc646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello! How can I assist you today?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import tool\n",
        "\n",
        "\n",
        "@tool\n",
        "def search(location: str) -> int:\n",
        "    \"\"\"Returns the weather of the given location.\"\"\"\n",
        "    return \"35 C\"\n",
        "\n",
        "tools = [search]"
      ],
      "metadata": {
        "id": "4NjB8cPscJXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini\")"
      ],
      "metadata": {
        "id": "yKrvmAVscNIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "response = model.invoke([HumanMessage(content=\"hi!\")])\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8PxEfX-cUmY",
        "outputId": "ce264462-fca4-45a6-a243-2983363b26fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_with_tools = model.bind_tools(tools)\n",
        "response = model_with_tools.invoke([HumanMessage(content=\"Hi!\")])\n",
        "\n",
        "print(f\"ContentString: {response.content}\")\n",
        "print(f\"ToolCalls: {response.tool_calls}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWjfxzEWcYjV",
        "outputId": "65b4d261-b34e-4a18-c3be-a3a45b19600c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ContentString: Hello! How can I assist you today?\n",
            "ToolCalls: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model_with_tools.invoke([HumanMessage(content=\"What's the weather in SF?\")])\n",
        "\n",
        "print(f\"ContentString: {response.content}\")\n",
        "print(f\"ToolCalls: {response.tool_calls}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRujrgnvccLn",
        "outputId": "905d0bd3-f4c9-44d5-f042-00743a3c2596"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ContentString: \n",
            "ToolCalls: [{'name': 'search', 'args': {'location': 'San Francisco'}, 'id': 'call_HUcavdRvpG2jMU5ByrAul1QA', 'type': 'tool_call'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "agent_executor = create_react_agent(model, tools)"
      ],
      "metadata": {
        "id": "oOO_KA2LcgZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent_executor.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"whats the weather in sf?\")]}\n",
        ")\n",
        "for m in response[\"messages\"]:\n",
        "  print(m)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S95jnXj8ckT8",
        "outputId": "c3a5d9d9-77e3-4d12-f056-ea6089413712"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='whats the weather in sf?' additional_kwargs={} response_metadata={} id='06955993-6cdd-40e7-ab2a-e64506d35e37'\n",
            "content='' additional_kwargs={'tool_calls': [{'id': 'call_ViO9kaJUql9evnDllSoQZcTf', 'function': {'arguments': '{\"location\":\"San Francisco\"}', 'name': 'search'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 51, 'total_tokens': 66, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f2cd28694a', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-e8ca1f16-b82a-4f21-bb08-2090dd62f63a-0' tool_calls=[{'name': 'search', 'args': {'location': 'San Francisco'}, 'id': 'call_ViO9kaJUql9evnDllSoQZcTf', 'type': 'tool_call'}] usage_metadata={'input_tokens': 51, 'output_tokens': 15, 'total_tokens': 66, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
            "content='35 C' name='search' id='988e3887-3db4-44ac-8808-8d897bc48613' tool_call_id='call_ViO9kaJUql9evnDllSoQZcTf'\n",
            "content='The weather in San Francisco is currently 35°C.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 74, 'total_tokens': 87, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f2cd28694a', 'finish_reason': 'stop', 'logprobs': None} id='run-53597f26-19bc-4cd3-9618-f4e5bcc3ec39-0' usage_metadata={'input_tokens': 74, 'output_tokens': 13, 'total_tokens': 87, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xO9zKm-YQWsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XUibqdvPNUL5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}